# hyperreduction.ecsw.hyperreduce { #skrom.hyperreduction.ecsw.hyperreduce }

`hyperreduction.ecsw.hyperreduce`

Implements the end-to-end hyper-reduction pipeline combining randomized SVD and bounded NNLS.

This module provides:
  - `hyperreduce`: function to perform hyper-reduction on a QoI matrix by:
    1. Optionally applying randomized SVD for dimensionality reduction
    2. Constructing bounded constraints for NNLS from projected data
    3. Solving a bounded NNLS problem via `NNLSSolver`
    4. Optionally visualizing singular value decay and NNLS coefficients

The `hyperreduce` folder contains utilities to reduce full-order models, including:
  - Randomized SVD preprocessing routines
  - Bounded NNLS solve integrations (`custom_nnls`)
  - Plotting helpers for diagnostic visualization of reduction errors

Dependencies:
  - NumPy for array operations
  - scikit-learn's `randomized_svd` for fast SVD
  - Matplotlib for plotting diagnostics
  - Custom `NNLSSolver` implementation in `custom_nnls`

Usage example:
```python
from hyperreduce.hyperreduce import hyperreduce
x, flag = hyperreduce(qoi_data, n_components=100, svd=True)
```

## Functions

| Name | Description |
| --- | --- |
| [hyperreduce](#skrom.hyperreduction.ecsw.hyperreduce.hyperreduce) | Perform hyper-reduction via randomized SVD followed by a bounded NNLS solve. |

### hyperreduce { #skrom.hyperreduction.ecsw.hyperreduce.hyperreduce }

```python
hyperreduction.ecsw.hyperreduce.hyperreduce(
    qoi,
    n_components=500,
    verbosity=2,
    plot=True,
    const_tol=1e-10,
    zero_tol=1e-14,
    svd=False,
)
```

Perform hyper-reduction via randomized SVD followed by a bounded NNLS solve.

The hyper-reduction pipeline includes:

1. (Optional) Randomized SVD of the quantity of interest (QoI) matrix to reduce its dimensionality.

2. Construction of lower and upper bound constraints around the projected right-hand side vector.

3. Bounded Non-Negative Least Squares (NNLS) solve using the `NNLSSolver`.

4. (Optional) Visualization of singular value decay and NNLS solution coefficients.

#### Parameters {.doc-section .doc-section-parameters}

| Name         | Type                                       | Description                                                                                                                                             | Default    |
|--------------|--------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|------------|
| qoi          | (array_like, shape(n_samples, n_features)) | Quantity of interest matrix on which hyper-reduction is performed.                                                                                      | _required_ |
| n_components | int                                        | Number of singular value decomposition components to retain when `svd=True`. Must be less than or equal to \min(n_samples, n_features). Default is 500. | `500`      |
| verbosity    | int                                        | Verbosity level for the NNLS solver. Higher values yield more diagnostic output. Default is 2.                                                          | `2`        |
| plot         | bool                                       | Whether to display plots for singular value decay and the NNLS solution vector. Default is True.                                                        | `True`     |
| const_tol    | float                                      | Tolerance used to define the half-gap around the average right-hand side vector for bounded constraints. Default is 1e-10.                              | `1e-10`    |
| zero_tol     | float                                      | Threshold below which NNLS solution coefficients are considered zero. Default is 1e-14.                                                                 | `1e-14`    |
| svd          | bool                                       | If True, apply randomized SVD preprocessing to `qoi`, otherwise solve NNLS directly on the original data. Default is False.                             | `False`    |

#### Returns {.doc-section .doc-section-returns}

| Name   | Type                                            | Description                                                                              |
|--------|-------------------------------------------------|------------------------------------------------------------------------------------------|
| x      | (ndarray, shape(n_features) or (n_components,)) | Coefficients from the bounded NNLS solve representing the hyper-reduction weights.       |
| flag   | int                                             | Exit status flag returned by the NNLS solver (e.g., 0 indicates successful convergence). |

#### Raises {.doc-section .doc-section-raises}

| Name   | Type       | Description                                                                       |
|--------|------------|-----------------------------------------------------------------------------------|
|        | ValueError | If `n_components` is greater than the minimum dimension of `qoi` when `svd=True`. |

#### Notes {.doc-section .doc-section-notes}

- The `randomized_svd` step (when enabled) uses oversampling and power iterations
  for stability and accuracy.
- Bounds for the NNLS solve are constructed as:

  .. math::
     b_{\mathrm{lower}} = d_q - \mathrm{const\_tol},
     \quad
     b_{\mathrm{upper}} = d_q + \mathrm{const\_tol},

  where

  .. math::
     d_q = V_q^{\mathrm{eff}} \mathbf{1}

  is the projected right-hand side vector.
- The final hyper-reduced error is computed internally as

  .. math::
     \frac{\|qoi\mathbf{1} - qoi\,x\|_2}{\|qoi\mathbf{1}\|_2}

  and printed for diagnostic purposes.

#### Examples {.doc-section .doc-section-examples}

```python
>>> import numpy as np
>>> from hyperreduce_module import hyperreduce
>>> data = np.random.rand(100, 200)
>>> x, flag = hyperreduce(data, n_components=50, svd=True, plot=False)
>>> print("Exit flag:", flag)
>>> print("Active basis vectors:", np.sum(x > 0))
```